{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchfm.dataset.avazu import AvazuDataset\n",
    "from torchfm.dataset.criteo import CriteoDataset\n",
    "from torchfm.dataset.movielens import MovieLens1MDataset, MovieLens20MDataset\n",
    "from torchfm.model.afi import AutomaticFeatureInteractionModel\n",
    "from torchfm.model.afm import AttentionalFactorizationMachineModel\n",
    "from torchfm.model.dcn import DeepCrossNetworkModel\n",
    "from torchfm.model.dfm import DeepFactorizationMachineModel\n",
    "from torchfm.model.ffm import FieldAwareFactorizationMachineModel\n",
    "from torchfm.model.fm import FactorizationMachineModel\n",
    "from torchfm.model.fnfm import FieldAwareNeuralFactorizationMachineModel\n",
    "from torchfm.model.fnn import FactorizationSupportedNeuralNetworkModel\n",
    "from torchfm.model.lr import LogisticRegressionModel\n",
    "from torchfm.model.ncf import NeuralCollaborativeFiltering\n",
    "from torchfm.model.nfm import NeuralFactorizationMachineModel\n",
    "from torchfm.model.pnn import ProductNeuralNetworkModel\n",
    "from torchfm.model.wd import WideAndDeepModel\n",
    "from torchfm.model.xdfm import ExtremeDeepFactorizationMachineModel\n",
    "from torchfm.model.afn import AdaptiveFactorizationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = MovieLens1MDataset('./data/ml-1m/ratings.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name, path):\n",
    "    if name == 'movielens1M':\n",
    "        return MovieLens1MDataset(path)\n",
    "    elif name == 'movielens20M':\n",
    "        return MovieLens20MDataset(path)\n",
    "    elif name == 'criteo':\n",
    "        return CriteoDataset(path)\n",
    "    elif name == 'avazu':\n",
    "        return AvazuDataset(path)\n",
    "    else:\n",
    "        raise ValueError('unknown dataset name: ' + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name, dataset):\n",
    "    \"\"\"\n",
    "    Hyperparameters are empirically determined, not opitmized.\n",
    "    \"\"\"\n",
    "    field_dims = dataset.field_dims\n",
    "    if name == 'lr':\n",
    "        return LogisticRegressionModel(field_dims)\n",
    "    elif name == 'fm':\n",
    "        return FactorizationMachineModel(field_dims, embed_dim=16)\n",
    "    elif name == 'ffm':\n",
    "        return FieldAwareFactorizationMachineModel(field_dims, embed_dim=4)\n",
    "    elif name == 'fnn':\n",
    "        return FactorizationSupportedNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'wd':\n",
    "        return WideAndDeepModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'ipnn':\n",
    "        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method='inner', dropout=0.2)\n",
    "    elif name == 'opnn':\n",
    "        return ProductNeuralNetworkModel(field_dims, embed_dim=16, mlp_dims=(16,), method='outer', dropout=0.2)\n",
    "    elif name == 'dcn':\n",
    "        return DeepCrossNetworkModel(field_dims, embed_dim=16, num_layers=3, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'nfm':\n",
    "        return NeuralFactorizationMachineModel(field_dims, embed_dim=64, mlp_dims=(64,), dropouts=(0.2, 0.2))\n",
    "    elif name == 'ncf':\n",
    "        # only supports MovieLens dataset because for other datasets user/item colums are indistinguishable\n",
    "        assert isinstance(dataset, MovieLens20MDataset) or isinstance(dataset, MovieLens1MDataset)\n",
    "        return NeuralCollaborativeFiltering(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2,\n",
    "                                            user_field_idx=dataset.user_field_idx,\n",
    "                                            item_field_idx=dataset.item_field_idx)\n",
    "    elif name == 'fnfm':\n",
    "        return FieldAwareNeuralFactorizationMachineModel(field_dims, embed_dim=4, mlp_dims=(64,), dropouts=(0.2, 0.2))\n",
    "    elif name == 'dfm':\n",
    "        return DeepFactorizationMachineModel(field_dims, embed_dim=16, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'xdfm':\n",
    "        return ExtremeDeepFactorizationMachineModel(\n",
    "            field_dims, embed_dim=16, cross_layer_sizes=(16, 16), split_half=False, mlp_dims=(16, 16), dropout=0.2)\n",
    "    elif name == 'afm':\n",
    "        return AttentionalFactorizationMachineModel(field_dims, embed_dim=16, attn_size=16, dropouts=(0.2, 0.2))\n",
    "    elif name == 'afi':\n",
    "        return AutomaticFeatureInteractionModel(\n",
    "            field_dims, embed_dim=16, atten_embed_dim=64, num_heads=2, num_layers=3, mlp_dims=(400, 400), dropouts=(0, 0, 0))\n",
    "    elif name == 'afn':\n",
    "        print(\"Model:AFN\")\n",
    "        return AdaptiveFactorizationNetwork(\n",
    "            field_dims, embed_dim=16, LNN_dim=1500, mlp_dims=(400, 400, 400), dropouts=(0, 0, 0))\n",
    "    else:\n",
    "        raise ValueError('unknown model name: ' + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper(object):\n",
    "\n",
    "    def __init__(self, num_trials, save_path):\n",
    "        self.num_trials = num_trials\n",
    "        self.trial_counter = 0\n",
    "        self.best_accuracy = 0\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def is_continuable(self, model, accuracy):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            self.trial_counter = 0\n",
    "            torch.save(model, self.save_path)\n",
    "            return True\n",
    "        elif self.trial_counter + 1 < self.num_trials:\n",
    "            self.trial_counter += 1\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, criterion, device, log_interval=100):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    tk0 = tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0)\n",
    "    for i, (fields, target) in enumerate(tk0):\n",
    "        fields, target = fields.to(device), target.to(device)\n",
    "        y = model(fields)\n",
    "        loss = criterion(y, target.float())\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            tk0.set_postfix(loss=total_loss / log_interval)\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    targets, predicts = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for fields, target in tqdm.tqdm(data_loader, smoothing=0, mininterval=1.0):\n",
    "            fields, target = fields.to(device), target.to(device)\n",
    "            y = model(fields)\n",
    "            targets.extend(target.tolist())\n",
    "            predicts.extend(y.tolist())\n",
    "    return roc_auc_score(targets, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    dataset_name,\n",
    "    dataset_path,\n",
    "    model_name,\n",
    "    epoch,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    weight_decay,\n",
    "    device,\n",
    "    save_dir):\n",
    "    device = torch.device(device)\n",
    "    dataset = get_dataset(dataset_name, dataset_path)\n",
    "    train_length = int(len(dataset) * 0.8)\n",
    "    valid_length = int(len(dataset) * 0.1)\n",
    "    test_length = len(dataset) - train_length - valid_length\n",
    "    train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        dataset, (train_length, valid_length, test_length))\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8)\n",
    "    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=8)\n",
    "    test_data_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=8)\n",
    "    model = get_model(model_name, dataset).to(device)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    early_stopper = EarlyStopper(num_trials=2, save_path=f'{save_dir}/{model_name}.pt')\n",
    "    for epoch_i in range(epoch):\n",
    "        train(model, optimizer, train_data_loader, criterion, device)\n",
    "        auc = test(model, valid_data_loader, device)\n",
    "        print('epoch:', epoch_i, 'validation: auc:', auc)\n",
    "        if not early_stopper.is_continuable(model, auc):\n",
    "            print(f'validation: best auc: {early_stopper.best_accuracy}')\n",
    "            break\n",
    "    auc = test(model, test_data_loader, device)\n",
    "    print(f'test auc: {auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:44<00:00,  8.78it/s, loss=0.834]\n",
      "100%|██████████| 49/49 [00:43<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 validation: auc: 0.5788358051055879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:44<00:00,  8.86it/s, loss=0.656]\n",
      "100%|██████████| 49/49 [00:43<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 validation: auc: 0.7053463096785169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:44<00:00,  8.85it/s, loss=0.582]\n",
      "100%|██████████| 49/49 [00:43<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 validation: auc: 0.7538042247562993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:18<00:00, 20.71it/s, loss=0.553]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=7'>8</a>\u001b[0m args\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=8'>9</a>\u001b[0m args\u001b[39m.\u001b[39msave_dir \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data/result\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=10'>11</a>\u001b[0m main(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=11'>12</a>\u001b[0m   args\u001b[39m.\u001b[39;49mdataset_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=12'>13</a>\u001b[0m   args\u001b[39m.\u001b[39;49mdataset_path,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=13'>14</a>\u001b[0m   args\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=14'>15</a>\u001b[0m   args\u001b[39m.\u001b[39;49mepoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=15'>16</a>\u001b[0m   args\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=16'>17</a>\u001b[0m   args\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=17'>18</a>\u001b[0m   args\u001b[39m.\u001b[39;49mweight_decay,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=18'>19</a>\u001b[0m   args\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000008?line=19'>20</a>\u001b[0m   args\u001b[39m.\u001b[39;49msave_dir)\n",
      "\u001b[1;32m/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb Cell 8'\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset_name, dataset_path, model_name, epoch, learning_rate, batch_size, weight_decay, device, save_dir)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000007?line=22'>23</a>\u001b[0m early_stopper \u001b[39m=\u001b[39m EarlyStopper(num_trials\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, save_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msave_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000007?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch_i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000007?line=24'>25</a>\u001b[0m     train(model, optimizer, train_data_loader, criterion, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000007?line=25'>26</a>\u001b[0m     auc \u001b[39m=\u001b[39m test(model, valid_data_loader, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000007?line=26'>27</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepoch:\u001b[39m\u001b[39m'\u001b[39m, epoch_i, \u001b[39m'\u001b[39m\u001b[39mvalidation: auc:\u001b[39m\u001b[39m'\u001b[39m, auc)\n",
      "\u001b[1;32m/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, data_loader, criterion, device, log_interval)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000005?line=2'>3</a>\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000005?line=3'>4</a>\u001b[0m tk0 \u001b[39m=\u001b[39m tqdm\u001b[39m.\u001b[39mtqdm(data_loader, smoothing\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, mininterval\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (fields, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tk0):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000005?line=5'>6</a>\u001b[0m     fields, target \u001b[39m=\u001b[39m fields\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gyoungwon-cho/dev/github/recommendation/pytorch-fm/test.ipynb#ch0000005?line=6'>7</a>\u001b[0m     y \u001b[39m=\u001b[39m model(fields)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1196\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1196\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1197\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \n\u001b[1;32m   1201\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/envs/pytorch3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1322\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1318\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1323\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1324\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9-dev/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.dataset_name = 'movielens1M'\n",
    "args.dataset_path = './data/ml-1m/ratings.dat'\n",
    "args.model_name = 'fm'\n",
    "args.epoch = 10\n",
    "args.learning_rate = 0.001\n",
    "args.batch_size = 2048\n",
    "args.weight_decay = 1e-6\n",
    "args.device = 'cpu'\n",
    "args.save_dir = './data/result'\n",
    "\n",
    "main(\n",
    "  args.dataset_name,\n",
    "  args.dataset_path,\n",
    "  args.model_name,\n",
    "  args.epoch,\n",
    "  args.learning_rate,\n",
    "  args.batch_size,\n",
    "  args.weight_decay,\n",
    "  args.device,\n",
    "  args.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('pytorch3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10+"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "819822aad1d7dd5a8911f6442f86af1dcc8bcd014a1dc82c30af569169ee7dac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
